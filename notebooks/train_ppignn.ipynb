{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use the Graphein submodule graphein.protein.features.sequence.embeddings, you need to install: biovec \n",
      "biovec cannot be installed via conda\n",
      "To use the Graphein submodule graphein.protein.visualisation, you need to install: pytorch3d \n",
      "To do so, use the following command: conda install -c pytorch3d pytorch3d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/27/23 11:31:00] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> To use the Graphein submodule graphein.protein.meshes, you need to        <a href=\"file:///Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/graphein/protein/meshes.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">meshes.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/graphein/protein/meshes.py#29\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         install: pytorch3d                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To do so, use the following command: conda install -c pytorch3d pytorch3d <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/27/23 11:31:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m To use the Graphein submodule graphein.protein.meshes, you need to        \u001b]8;id=814173;file:///Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/graphein/protein/meshes.py\u001b\\\u001b[2mmeshes.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=508367;file:///Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/graphein/protein/meshes.py#29\u001b\\\u001b[2m29\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         install: pytorch3d                                                        \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To do so, use the following command: conda install -c pytorch3d pytorch3d \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from functools import partial\n",
    "from graphein.protein.config import ProteinGraphConfig\n",
    "from graphein.protein.edges.distance import (add_distance_threshold,\n",
    "                                             add_peptide_bonds,\n",
    "                                             add_hydrogen_bond_interactions,\n",
    "                                             add_disulfide_interactions,\n",
    "                                             add_ionic_interactions,\n",
    "                                             add_aromatic_interactions,\n",
    "                                             add_aromatic_sulphur_interactions,\n",
    "                                             add_cation_pi_interactions\n",
    "                                            )\n",
    "from graphein.protein.graphs import construct_graph\n",
    "from graphein.protein.features.sequence.embeddings import esm_residue_embedding\n",
    "from graphein.protein.visualisation import plotly_protein_structure_graph\n",
    "from src.processing.graph import convert_nx_to_pyg_data\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.dataset import PPIDataModule\n",
    "from src.models import LightningGCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(npy_file)\n",
    "# print(data.shape)\n",
    "# processed_pdb_codes = [path.split('.')[0] for path in os.listdir(processed_dir)]\n",
    "\n",
    "# idx_to_del = []\n",
    "# for i in range(len(data)):\n",
    "#     if data[i, 2] not in processed_pdb_codes or data[i, 5] not in processed_pdb_codes:\n",
    "#         idx_to_del.append(i)\n",
    "# data = np.delete(data, idx_to_del, 0)\n",
    "# print(data.shape)\n",
    "# np.save(npy_file, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 17553\n",
      "Test len: 4389\n"
     ]
    }
   ],
   "source": [
    "npy_file =  '../data/preprocessed/human_data.npy'\n",
    "processed_dir =  '../data/graphs/pan_human'\n",
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "EPOCHS = 50\n",
    "ppi_data = PPIDataModule(npy_file=npy_file, processed_dir=processed_dir, batch_size=BATCH_SIZE)\n",
    "ppi_data.setup(train_size=0.8, random_seed=SEED)\n",
    "\n",
    "train_loader = ppi_data.train_dataloader()\n",
    "print(\"Train len:\", len(ppi_data.train))\n",
    "test_loader = ppi_data.test_dataloader()\n",
    "print(\"Test len:\",len(ppi_data.test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "   | Name       | Type           | Params\n",
      "-----------------------------------------------\n",
      "0  | pro1_conv1 | GCNConv        | 1.0 M \n",
      "1  | pro1_fc1   | Linear         | 131 K \n",
      "2  | pro2_conv1 | GCNConv        | 1.0 M \n",
      "3  | pro2_fc1   | Linear         | 131 K \n",
      "4  | relu       | LeakyReLU      | 0     \n",
      "5  | dropout    | Dropout        | 0     \n",
      "6  | sigmoid    | Sigmoid        | 0     \n",
      "7  | fc1        | Linear         | 65.8 K\n",
      "8  | fc2        | Linear         | 16.4 K\n",
      "9  | out        | Linear         | 65    \n",
      "10 | loss_fn    | MSELoss        | 0     \n",
      "11 | accuracy   | BinaryAccuracy | 0     \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.776     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc1843bdc484a89a2c8dc68d8c43365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgbrasier/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sequence_A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m tb_logger \u001b[39m=\u001b[39m pl_loggers\u001b[39m.\u001b[39mTensorBoardLogger(save_dir\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpan-human-data\u001b[39m\u001b[39m'\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mppi_gnn\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39mEPOCHS, logger\u001b[39m=\u001b[39mtb_logger, callbacks\u001b[39m=\u001b[39m[checkpoint_callback], log_every_n_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, check_val_every_n_epoch\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m trainer\u001b[39m.\u001b[39mfit(ppigcnn, train_dataloaders\u001b[39m=\u001b[39mtrain_loader, val_dataloaders\u001b[39m=\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    737\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1166\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1168\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1274\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1273\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1276\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1343\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1347\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 155\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:127\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    126\u001b[0m     batch_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mcurrent\u001b[39m.\u001b[39mready\n\u001b[0;32m--> 127\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     batch_idx, batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetching_function()\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:263\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    261\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_iter)\n\u001b[1;32m    264\u001b[0m         \u001b[39m# consume the batch we just fetched\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:277\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_next_batch\u001b[39m(\u001b[39mself\u001b[39m, iterator: Iterator) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     start_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_fetch_start()\n\u001b[0;32m--> 277\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetched \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    279\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefetch_batches \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_len:\n\u001b[1;32m    280\u001b[0m         \u001b[39m# when we don't prefetch but the dataloader is sized, we use the length for `done`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:34\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(elem)(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Sequence) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)]\n\u001b[1;32m     36\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataLoader found invalid type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(elem)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(elem)(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Sequence) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)]\n\u001b[1;32m     36\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataLoader found invalid type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(elem)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:32\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: \u001b[39mself\u001b[39m([data[key] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     31\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39;49m(elem)(\u001b[39m*\u001b[39;49m(\u001b[39mself\u001b[39;49m(s) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mbatch)))\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Sequence) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)]\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:32\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: \u001b[39mself\u001b[39m([data[key] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     31\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(elem)(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39;49m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Sequence) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)]\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:19\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[1;32m     20\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[1;32m     21\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[1;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[1;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[1;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[1;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/data/collate.py:70\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m exclude_keys:  \u001b[39m# Do not include top-level attribute.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m values \u001b[39m=\u001b[39m [store[attr] \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m stores]\n\u001b[1;32m     72\u001b[0m \u001b[39m# The `num_nodes` attribute needs special treatment, as we need to\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m# sum their values up instead of merging them to a list:\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnum_nodes\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/data/collate.py:70\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m exclude_keys:  \u001b[39m# Do not include top-level attribute.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m values \u001b[39m=\u001b[39m [store[attr] \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m stores]\n\u001b[1;32m     72\u001b[0m \u001b[39m# The `num_nodes` attribute needs special treatment, as we need to\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m# sum their values up instead of merging them to a list:\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnum_nodes\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tcrbind/lib/python3.8/site-packages/torch_geometric/data/storage.py:81\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sequence_A'"
     ]
    }
   ],
   "source": [
    "ppigcnn = LightningGCNN()\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=os.path.join('checkpoint','pan-human-data', 'ppi_gnn'), save_top_k=1, monitor='val_acc')\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=os.path.join('logs','pan-human-data'), name='ppi_gnn')\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=tb_logger, callbacks=[checkpoint_callback], log_every_n_steps=10, check_val_every_n_epoch=1)\n",
    "trainer.fit(ppigcnn, train_dataloaders=train_loader, val_dataloaders=test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcrbind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "560dd1d7156606f13a7445ff69c7051db43d809c46749248ec14e34c5b781448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
